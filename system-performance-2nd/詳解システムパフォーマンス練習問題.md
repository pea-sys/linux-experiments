## メソドロジ

- 1. パフォーマンスの基本用語についての以下の問いに答えなさい

  - IOPS とは何か  
    (答)秒あたりの入出力回数

  * 使用率とは何か  
    (答)リソースがどの程度の割合使用されているかを表した指標
  * 飽和とは何か  
    (答)リソースで即時処理できずにキューイングされた処理
  * レイテンシとは何か  
    (答)目的の処理が実行されるまでの時間
  * マイクロベンチマーキングとは何か  
    (答)特定処理の処理速度を測定する手段

- 2. あなたの環境で使うメソドロジを５つ選びなさい。実践する順序で並べ、個々のメソドロジを選んだ理由を説明しなさい
  - 1. 問題の記述  
       理由)  
       スタンドアローンの組み込みソフトを提供しているため、リモートでのログ等の確認が出来ない。  
       まずは、電話での状況確認になる。
  - 2. 科学的メソッド  
       理由)  
       電話超しの問診で特定できない場合は、ログを送ってもらう。  
       ログから遅くなっている箇所はある程度絞れるのと、リソースの状況もある程度掴めるようになるので仮説が立てられる。
  - 3. USE メソッド  
       理由)  
        これまでの経験に基づいた分析で原因が分からなかった場合は、
       手続きに沿った定型の診断を行う。USE メソッドは手早く出来る。
  - 4. ドリルダウン分析  
       理由)  
       定型の簡易診断で原因が掴めない場合は、高次から掘り下げを繰り返し、原因特定を行う
  - 5. パフォーマンスマントラ  
       理由)  
        原因が特定できたらパフォーマンスマントラに沿って対策を検討・実施する

* 3. 唯一のパフォーマンス指標として平均レイテンシを使ったときの問題点を簡潔に説明しなさい、99 パーセンタイルを含めれば、その問題は解決できるか  
     解答)  
     問題点は統計値として平均を採用している点。パフォーマンスにばらつきがある場合は、悪い時のパフォーマンスは平均によりほとんど隠される可能性が高い。  
     また、99 パーセントタイルは単峰分布を対象としたものであるが、多くの場合、システムパフォーマンスは 2 峰以上の分布であるため、表現として適していない場合がある。

## オペレーティングシステム

- 1. OS 用語について以下の問いに応えなさい
  - プロセス、スレッド、タスクの違いは何か
    解答)  
    プロセスはプログラムの実行環境。スレッドはスケジューリング可能な実行コンテキストであり、プロセスは複数のスレッドを持ちうる。タスクは処理の実行単位である。
  - モードスイッチとコンテキストスイッチとは何か  
    解答)  
    モードスイッチはカーネルモードとユーザーモードを切り替えるスイッチ。コンテキストスイッチはスレッドやプロセスを切り替えるスイッチ
  - ページングとスワッピングの違いは何か  
    解答)  
    ページングは仮想メモリのデータを物理メモリに読み書きすること。スワッピングはメモリとディスクのデータを交換し、実メモリより多くのデータを透過的に扱う。
  - I/O バウンドワークロードと CPU バウンドワークロードの違いは何か  
    解答)  
    I/O バウンドワークロードは CPU にほとんど負荷をかけないが、CPU バウンドワークロードは CPU への負担が大きい。
- 2. コンセプトについて以下の問いに答えなさい

  - カーネルの役割を説明しなさい  
    解答)
    カーネルは OS の中核となる機能を有する。
  - システムコールの役割を説明しなさい  
    解答)  
    カーネルモードで動く処理のインターフェース提供する
  - VFS の役割と I/O スタック内での位置を説明しなさい  
    解答)  
    ファイルシステムを抽象化する役割で、ファイルシステムの上層に位置する

- 3. 難易度の高い以下の問いに答えなさい

  - スレッドが CPU を手放す理由を列挙しなさい  
    解答)
    - 割込み処理を可能にするため
    * 消費電力の浪費を防ぐため
    * 非同期処理を可能にするため
    * モードスイッチを可能にするため
  - 仮想メモリとデマンドページングの利点を説明しなさい  
    解答)  
    仮想メモリにより実メモリより多くのデータを取り扱える  
    仮想メモリへの読み書きは時間が掛かるため、デマンドページングにより実際に必要になったタイミングで最小限のページのみを実メモリにロードして、最小限のコストでデータを読み書き可能とする。

## 可観測性ツール

- 1. 静的パフォーマンスツールの例を挙げなさい  
     解答)  
     df, dmesg, sysctl
- 2. プロファイリングとは何か  
     解答)  
     分析手法。測定し、問題点を検出・特定するために使用する。
- 3. プロファイラが 100Hz ではなく 99Hz を使うのはなぜか  
     解答)  
     ターゲットのサンプリングと歩調が合わないようにするため。  
     計測値がぶれやすくなる。
- 4. トレーシングとは何か  
     解答)  
     処理やデータの流れを追跡すること
- 5. 静的インストルメンテーションとは何か  
     解答)  
     ハードコードされたトレーシングポイント
- 6. 動的インストルメンテーションが重要な理由を説明しなさい  
     解答)  
     本番稼働しているカーネルから静的インストール面テーションでは取り出せない任意の情報を取り出せる。問題の観察をするための最後の手段として重要。
- 7. トレースポイントと kprobe の違いは何か  
     解答)  
     トレースポイントとは静的インストルメンテーションのイベントソース  
     kprobe は動的インストルメンテーションのイベントソース
- 8. 以下の作業で予想される CPU のオーバーヘッド(低いか普通か高いか)を説明しなさい

  - ディスクの IOPS カウンタ(iostat(1)で見られるもの)  
    解答)  
    オーバーヘッドは低い。カーネルがデフォルトで有効にしているため。
  - トレーシングポイントが kprobe を使ったディスク I/O ごとのトレーシング  
    解答)  
    kretprobe を使用することになるのでオーバーヘッドは低くないが、ディスク I/O のコストと比較すると普通程度と予想。
  - トレーシングポイントが kprobe を使ったコンテキストスイッチごとのトレーシング  
     解答)  
    関数開始ポイントのみのトーレシングポイントになるのでオーバーヘッドは低い。
  - トレーシングポイントが kprobe を使ったプロセスの起動(execve(2))ごとのトレーシング  
    解答)  
    関数開始ポイントのみのトーレシングポイントになるのでオーバーヘッドは低い。
  - uprobe を使った libc_malloc()が呼び出しごとのトレーシング  
    解答)  
    関数開始ポイントのみのトーレシングポイントになるのでオーバーヘッドは低い。

- 9. パフォーマンス分析で PMC に価値がある理由を説明しなさい  
     解答)  
     PMC でのみ得られるプロセッサのプロファイル情報から、CPU の使い方を最適化できる。

- 10. 可観測性ツールが与えられたとき、どうすればそれが使っているインストルメンテーションを明らかにできるか説明しなさい  
      解答)  
      ツールが提供する統計量と一致する情報を提供する標準的なツールを探し出し、ソースコードを辿る。

## アプリケーション

- 1. 用語についての以下の問いに答えなさい

  - キャッシュとは何か  
    解答)  
    1 度アクセスした情報を高速にアクセスできる位置に一時的に保存しておく方法
  - リングバッファとは何か  
    解答)  
    ローテーションでメモリを使用するバッファ  
    メモリサイズが固定なので、メモリ確保のコストがない

  - スピンロックとは何か  
    解答)  
    複数のスレッドやプロセスが共有リソースへのアクセスを制御するために使用する。リソースが他のスレッドやプロセスによって利用可能になるのを待つ代わりに、ロック解除されるまで継続的に試行し続ける。
  - アダプティブミューテックスロックとは何か  
    解答)
    複数のスレッドが共有リソースへのアクセスを制御するために使用する。待機時間が短い場合にはスピンロックのように動作し、長い場合はスレッドをスリープさせて、CPU の無駄遣いを防ぐ。
  - 並行実行と並列処理の違いは何か  
     解答)
    　　並行実行は複数タスクが on-CPU されるとは限らないが、並列処理は複数タスクが on-CPU になる
  - CPU アフィニティとは何か  
    解答)  
    特定のプロセスまたはスレッドが実行される CPU コアを制御する概念。リソース制限やパフォーマンス向上を目的としている。

- 2. コンセプトについての以下の問いに答えなさい

  - 大きな I/O サイズを使うことの一般的な長所・短所は何か  
    解答)  
    長所：I/O サイズが大きくなることで I/O の頻度が減り、CPU の待ち時間が減る。一方で、余計なメモリを確保し、リソースを無駄遣いする場合もある。
  - ロックのハッシュテーブルは何のために使われているか  
    解答)  
    1 個のロックリソースを共有することによるロック競合を回避しつつ、対象リソース毎にロックリソースを用意した場合のロック制御の CPU 負荷の増大化を回避するための使用。

  - コンパイル言語、インタープリタ言語、仮想マシンを使う言語の実行時の一般的なパフォーマンス特性を説明しなさい  
    解答)  
    コンパイル言語は CPU の実行可能なバイナリファイルが生成されるため、パフォーマンスは良い傾向にある。インタープリタ言語はプログラム実行時に動的に機械語に変換するため、パフォーマンスが低い傾向にある。仮想マシンはコンパイルとインタープリタの両方をサポートしている。仮想マシン上で動作するためコンパイルをしたとしても、コンパイル言語よりはパフォーマンスは落ちる。

  - ガベージコレクションの役割とパフォーマンスに与える影響について答えなさい  
    解答)  
    不要になったマネージドオブジェクトの使用メモリを自動的に解法し、大部分のメモリ管理を自動管理する。ガベージコレクションは比較的コストの大きい処理であるため、CPU 負荷が高く、他の処理を遅くする可能性がある。

* 3. アプリケーションを選び、以下の基本的な問いに答えなさい  
     選択したアプリケーション:zopfli  
     https://github.com/google/zopfli/blob/master/README.zopflipng

  - そのアプリケーションの役割は何か  
    解答)  
    png の圧縮

  - そのアプリケーションは別々のオペレーションとして何をしているか  
    解答)  
    png のロード

  - そのアプリケーションはユーザーモードとカーネルモードのどちらで実行されるか  
    解答)  
    ユーザーモード

  - そのアプリケーションはどのように構成されているか。パフォーマンスに関して、どのようなオプションがあるか  
    解答)  
    イテレーションを指定して、イテレーション回数のを枝切りが可能

  - そのアプリケーションはどのようなパフォーマンス指標を提供しているか  
    解答)  
    圧縮率

  - そのアプリケーションはどのようなログを作っているか。ログにパフォーマンス指標は含まれているか  
    解答)  
    ログはなく、標準出力のみ。

  - そのアプリケーションの最新バージョンはパフォーマンス問題を解決しているか  
    解答)  
    はい。ただし、もうメンテナンスは数年おこなわれていない。

  - そのアプリケーションに既知のパフォーマンスバグはあるか  
    解答)  
    圧縮率が増えた場合に、レポートの圧縮率がアンダーフローを起こすバグがある
  - そのアプリケーションにコミュニティはあるか。パフォーマンスコミュニティはどうか  
    解答)  
    Github がコミュニティになっている、パフォーマンスコミュニティの存在は認識していない。

  - そのアプリケーションについての本はあるか。パフォーマンスについての本はどうか  
    解答)  
    本はない

  - そのアプリケーションのパフォーマンスについて有名なエキスパートはいるか。いるなら誰か  
    解答)  
    いない

* 4. 負荷のかかっているアプリケーションを選び、以下の作業をしなさい（多くのものは動的トレーシングを必要とする)  
     選択したアプリケーション:zopfli

  - 計測を行う前に、そのアプリケーションが CPU バウンドか I/O バウンドか予想しなさい。また、その理由を説明しなさい。  
    解答)  
    CPU バウンド。zopfli でサポートしている deflate 圧縮は通常 CPU コストの高さから試行回数を 1 回で打ち切るようにしているが、zopfli は圧縮試行を何回も行うため。

  - CPU バウンドか I/O バウンドかを可観測性ツールで明らかにしなさい  
    解答)  
    top コマンドで確認したところ、zopflipng プロセスの 動作中の大部分の時間において CPU 使用率が 100%になっている

    ```
    PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
    590 masami    20   0   10288   7764   3624 R  99.7   0.2   0:13.43 zopflipng
    441 root      20   0  967556  84808  26316 S   0.3   2.1   0:30.21 python3.10
    447 root      20   0   43180  37628  10156 S   0.3   0.9   0:12.75 python3
    588 masami    20   0    7796   3704   3108 R   0.3   0.1   0:00.10 top
    ・・・
    ```

    perf コマンドで確認すると、1.90 insn per cycle なので、2core をほとんど CPU 命令に使い切っている状況

    ```
    masami@DESKTOP-L18OTEK /m/c/U/user [255]> sudo perf stat -a -- sleep 10
    [sudo] password for masami:

    Performance counter stats for 'system wide':

          40020.11 msec cpu-clock                 #    4.000 CPUs utilized
               683      context-switches          #   17.066 /sec
                14      cpu-migrations            #    0.350 /sec
              3960      page-faults               #   98.950 /sec
       16216576252      cycles                    #    0.405 GHz
       30786259882      instructions              #    1.90  insn per cycle
        7054228214      branches                  #  176.267 M/sec
         169069741      branch-misses             #    2.40% of all branches

      10.004642769 seconds time elapsed
    ```

  - そのアプリケーションの CPU フレームグラフを作りなさい。この課題では、シンボルとスタックトレースの修復が必要になる場合がある。もっともホットな CPU コードパスは何か  
     解答)  
     プリインストールされている zopfli 実行中のフレームグラフを作ったところ、シンボルが Unknown で追跡が難しい状況

    ```sh
    git clone https://github.com/brendangregg/FlameGraph
    cd FlameGraph
    perf record -F 99 -a -g -- sleep 60
    perf script | ./stackcollapse-perf.pl > out.perf-folded
    ./flamegraph.pl out.perf-folded > perf-kernel.svg
    ```

    ![1](https://github.com/pea-sys/linux-experiments/assets/49807271/97a64941-885b-4196-9442-b241dc07fd64)  
    ネイティブなプログラムのシンボルを追跡するためには再コンパイルが必要？
    次にあるように、Zopfli のコンパイルは難しい状況。
    https://github.com/google/zopfli/issues/143  
    代わりに linux コマンドでも見てみようと思い、カーネルヘッダー をコンパイルしたが、メモリアクセス違反でコンパイルが中断(6 回延べ 15 時間を消費)し、作業中止  
    WSL のリポジトリに Issue は立てておいた。

  - そのアプリケーションの off-CPU フレームグラフを作りなさい。要求の処理中にブロックする時間が最も長いイベントは何か(アイドルスタックは無視する)  
    解答)  
    上記の通り、カーネルヘッダーのコンパイルが出来ないため、bcc ツールに含まれる offcputime が実行不可。スキップします。

  * 実行する I/O のサイズ(例えば、ファイルシステムの読み書き、ネットワークの送受信)の特性を説明しなさい  
    解答)  
    サイズが大きな I/O は時間が掛かるのでレイテンシに影響を与える可能性がある。サイズが小さい I/O の場合、頻繁にシステムコールを使用し、個々の処理のターンアラウンドタイムが増えている可能性がある。適切なバッファサイズを確保し、最適な I/O サイズと頻度に調整することが望ましい。

  * そのアプリケーションはキャッシュを持っているか。あるなら、サイズとヒット率を明らかにしなさい  
     解答)  
    　キャッシュヒット率は 78%

    ```
      masami@DESKTOP-L18OTEK /m/c/U/user> perf stat -e cycles,instructions,cache-references,cache-misses zopfli "/mnt/c/Users/
      user/OneDrive/デスクトップ/1.png"

      Performance counter stats for 'zopfli /mnt/c/Users/user/OneDrive/デスクトップ/1.png':

              395174418      cycles:u
              793660521      instructions:u            #    2.01  insn per cycle
                4171569      cache-references:u
                  945894      cache-misses:u            #   22.675 % of all cache refs

            0.274801520 seconds time elapsed

            0.242133000 seconds user
            0.010088000 seconds sys
    ```

    特定アプリで使用しているキャッシュサイズの確認方法は不明  
    WSL で利用できるキャッシュサイズは次の通り

    ```
    masami@DESKTOP-L18OTEK /m/c/U/user> vmstat -s | grep "cache"
       374344 K swap cache
    ```

  * そのアプリケーションを実行するオペレーションのレイテンシ(応答時間)を計測しなさい。平均、最小値、最大値、全体の分布を示しなさい  
    解答)  
    測定結果

    ```
    masami@DESKTOP-L18OTEK /m/c/U/user> time zopfli --i100 "/mnt/c/Users/user/OneDrive/デスクトップ/globe-scene-fish-bowl-pngcrush.png"
    ________________________________________________________
    Executed in    5.05 secs    fish           external
    Executed in    5.50 secs    fish           external
    Executed in    4.98 secs    fish           external
    Executed in    4.99 secs    fish           external
    Executed in    5.15 secs    fish           external
    Executed in    5.27 secs    fish           external
    Executed in    8.61 secs    fish           external
    Executed in    4.91 secs    fish           external
    Executed in    4.82 secs    fish           external
    Executed in    5.10 secs    fish           external
    ```

    平均 5.475secs 最大値 8.61secs 最小値 4.82secs 分散 1.279

    ![2](https://github.com/pea-sys/linux-experiments/assets/49807271/08445fd0-8472-44c1-a84e-8718e12dad90)

  * オペレーションのドリルダウン分析を行い、レイテンシの主要部がどこに発生しているかを解析しなさい  
    解答)  
    zopflipng を対象とする

    - CPU バウンドか I/O バウンドか  
      →CPU バウンド
    - どの処理に時間が掛かっているか  
      → 今のところコンパイル出来ないため関数レベルでは不明

  * そのアプリケーションのワークロード特性を明らかにしなさい(特に誰がと何を)  
     解答)
    - zopflipng  
      諸事情により zopflipng はコンパイルが困難なので関数情報は得られないが、シングルスレッドで動作している圧縮アルゴリズムの計算がボトルネックになっていることが明らかである。  
      なので、圧縮アルゴリズムのマルチスレッド化や、より計算能力の高い CPU を使用することで  
      パフォーマンスの改善が見込まれる。
      次の通り、並列動作はしない

```
masami@DESKTOP-L18OTEK /m/c/U/user> mpstat -P ALL 1
Linux 5.15.90.1-microsoft-standard-WSL2 (DESKTOP-L18OTEK)       10/08/23        _x86_64_        (4 CPU)
16:35:02     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
16:35:03     all   24.94    0.00    0.00    0.00    0.00    0.25    0.00    0.00    0.00   74.81
16:35:03       0    0.00    0.00    0.00    0.00    0.00    0.99    0.00    0.00    0.00   99.01
16:35:03       1  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00
16:35:03       2    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
16:35:03       3    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00

16:35:54     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
16:35:55     all   25.06    0.00    0.25    0.00    0.00    0.00    0.00    0.00    0.00   74.69
16:35:55       0  100.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00
16:35:55       1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
16:35:55       2    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
16:35:55       3    0.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   99.00
```

CPU はユーザーモードでの処理に多くの時間を割いている

```
masami@DESKTOP-L18OTEK /m/c/U/user> mpstat -P ALL 1
Linux 5.15.90.1-microsoft-standard-WSL2 (DESKTOP-L18OTEK)       10/08/23        _x86_64_        (4 CPU)
16:40:21      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
16:40:22        0       442    1.00    0.00    0.00    0.00    1.00     2  python3.10
16:40:22        0       470    1.00    0.00    0.00    0.00    1.00     3  python3
16:40:22     1000      3125  100.00    0.00    0.00    0.00  100.00     0  zopflipng

16:41:01      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
16:41:02        0       140    1.00    0.00    0.00    0.00    1.00     2  snapd
16:41:02     1000      3125  100.00    0.00    0.00    0.00  100.00     0  zopflipng
```

分岐予測ミスは少なく、スイッチの回数も少ない。単純に計算処理に時間が掛かっている

```
masami@DESKTOP-L18OTEK /m/c/U/user [255]> sudo perf stat -a -- sleep 20
[sudo] password for masami:

 Performance counter stats for 'system wide':

          80036.55 msec cpu-clock                 #    4.000 CPUs utilized
              1282      context-switches          #   16.018 /sec
                24      cpu-migrations            #    0.300 /sec
               828      page-faults               #   10.345 /sec
       21211226527      cycles                    #    0.265 GHz
       42189881874      instructions              #    1.99  insn per cycle
        9457279816      branches                  #  118.162 M/sec
         169995360      branch-misses             #    1.80% of all branches
```

- 静的パフォーマンスチューニングチェックリストをすべてチェックしなさい  
  解答)

  - バージョン不明(多分 1.0.3)  
    以下にある通り、バージョンの確認手段が提供されていない  
    https://github.com/google/zopfli/pull/139

  * アプリケーションの既知のパフォーマンス障害は何か  
    巨大な画像ファイルを圧縮しようとすると、メモリ不足になる

  * アプリケーションはどのように構成されているか  
    zopfli_bin.c がエントリポイントとなり、defalte.c 経由で lz77 圧縮処理を行い、gzip_container でパッケージングを行っている。

  * アプリケーションはオブジェクトのキャッシュを使用しているか、サイズはどのくらいか  
    ZopfliInitCache オブジェクトを使用している。サイズは入力するファイルサイズに応じて確保している。
  * アプリケーションは特別なモードで実行されているか  
    されていない

  * アプリケーションはどのシステムライブラリを使用しているか
    - 標準ライブラリ
    - 標準入出力ライブラリ
  * アプリケーションはどのメモリアロケータを使っているか  
    malloc
  * アプリケーションはヒープのためにラージページを使うように構成されているか  
    構成されていない
  * アプリケーションはコンパイルされているか。コンパイラーのバージョンはいくつか。コンパイラオプションと最適化はどうなっているか  
    gcc で最適化オプション O3 を使用してコンパイルしている
  * ネイティブコードに高度な命令(intel SSE/SIMD ベクトル命令)は含まれていないか  
    CPU 固有の命令は含まれていない
  * アプリケーションが縮退モードで動作していないか  
    縮退モードは存在しない
  * CPU, メモリ,ファイルシステム,ディスク,ネットワークの利用にシステムから設定された制限、リソースコントロールはないか  
    OS の制限は存在するが、アプリ固有の設定はない。

- そのアプリケーションは並列実行されるか。同期プリミティブの使われ方を調べなさい  
  解答)  
  mpstat で確認した結果、並列実行されていない。よって同期プリミティブも使われていない。

- 5. (高度)複数のスレッド状態分析欄を持ち、それぞれで使った時間を表示する tsastat(8)という Linux 用のツールを開発しなさい、このツールは、pidstat(1)と同じように動作し、変化の過程を出力できるものとする  
     解答)

## CPU

- 1. CPU の用語について以下の問いに答えなさい

  - プロセスとプロセッサの違いは何か  
    解答)  
    プロセスは論理的な処理単位。プロセッサは物理的な計算機。
  - ハードウェアスレッドとは何か  
    解答)  
    1 つのコア上で複数のスレッドの並列実行をサポートする CPU アーキテクチャ

  - ランキューとは何か  
    解答)  
    CPU が与えられるのを待っている実行可能スレッドのキュー。

  - ユーザー時間とカーネル時間の違いは何か  
    解答)  
    ユーザーモードまたはカーネルモードで CPU 実行した時間。

* 2. コンセプトについて以下の問いに答えなさい

  - CPU の使用率と飽和を説明しなさい  
    解答)  
    使用率は一定時間内に CPU がビジーになっていた時間の割合。  
    飽和は CPU 使用率上限に達した状態。

  - 命令パイプラインが CPU の使用率をどのようにして上げるか説明し
    なさい  
    解答)  
    異なる命令を並列実行することで CPU の使用率を上げる

  - プロセッサ命令幅が CPU の使用率をどのようにして上げるか説明しなさい  
    解答)  
    命令幅の増加することで並列実行できる命令の数が増えて、CPU の使用率が上がる

  - マルチプロセス、マルチスレッディングモデルの利点を説明しなさい  
    解答)  
    マルチプロセスはプロセス別に独立性を維持したまま開発することが出来るので、開発難易度が低い。また、１つのプロセスが強制終了しても他のプロセスに影響を与えにくい。  
    マルチスレッディングモデルは、メモリの消費量が少なく、処理速度も早い傾向にある。

* 3. 以下の少し難しい問いに答えなさい

  - システム CPU が能力以上に実行可能な処理を抱えているときに何が起きるか、アプリケーションのパフォーマンスに対する影響を含めて説明しなさい  
    解答)  
    命令処理がランキューに溜まっている状況となるため、アプリケーションは CPU バウンドのパフォーマンス定価の影響を受けることになる

  * 実行すべき実行可能な処理がないとき、CPU はなにをするか  
    解答)  
    アイドルスレッドにより、CPU は節電モードに入る、

  * CPU のパフォーマンスの問題かもしれないものの処理をゆだねられたときに、調査の初期の段階で使う 2 種類のメソドロジを挙げ、その理由を説明しなさい。  
    解答)  
     USE メソッドにより、すべてのコンポーネントを対象としてボトルネックやエラーを見つける。その後、プロファイリングにより解析対象の具体像を構築する。

* 4. あなたの環境のために次の作業をしなさい

  - CPU リソースのための USE メソッドチェックリスト。個々の指標の取得方法(例えば、どのコマンドを実行するか)と結果の解釈方法も入れること。追加のソフトウェア製品をインストールしたり使ったりする前に、OS が提供する既存の可観測性ツールを使うようにしなさい。  
    解答)
    - 使用率・・・mpstat(linux マシン購入後に実施)
    - 飽和度・・・vmstat の r を見る
    - CPU エラー・・・ECC メモリに対応していないのでチェック不可

  * CPU リソースのワークロードの特性の把握チェックリスト。個々の指標の取得方法を入れること。まず OS が提供する既存の可観測性ツールを使うようにしなさい。  
    解答)

    - ロードアベレージ(使用率+飽和度):htop で load average の項目を見る
    - ユーザー時間とシステム時間の比較:pidstats で%usr と%system の項目を見る
    - システムコールの頻度:dtrace
    - 自発的なコンテキストスイッチの頻度

    ```
    masami@DESKTOP-L18OTEK /m/c/W/system32 [1]> ps
    PID TTY          TIME CMD
    395 pts/0    00:00:10 fish
    952 pts/0    00:00:00 ps
    masami@DESKTOP-L18OTEK /m/c/W/system32> cat /proc/395/status | grep ctxt
    voluntary_ctxt_switches:        15838
    nonvoluntary_ctxt_switches:     61
    ```

    - 割込みの頻度:mpstat の irq

    ```
    masami@DESKTOP-L18OTEK /m/c/W/system32> mpstat -P ALL 1
    Linux 5.15.90.1-microsoft-standard-WSL2 (DESKTOP-L18OTEK)       10/14/23        _x86_64_        (4 CPU)

    18:31:08     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
    18:31:09     all    0.50    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.50
    18:31:09       0    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
    18:31:09       1    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00
    18:31:09       2    0.99    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.01
    18:31:09       3    0.99    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   99.01
    ```

* 5. 以下の作業をしなさい。

  - ディスク/ロックの大きな負荷がなく、負荷が安定している以下のシステムのロードアベレージを計算しなさい。

    - システムは 64 個の CPU を搭載している
    - システム全体の CPU 使用率は 50%である
    - システム全体での CPU の飽和(実行可能でキューイングされたスレッド数の平均で計測する)は 2.0 になっている  
      解答)  
      ロードアベレージは実行待ちプロセス数の平均数なので 2
      といいたいところですが、同一プロセスの複数スレッドが同じ CPU に割り当てられることもあるので、分からないような気がします・・・

  * アプリケーションを選び、そのユーザーレベル CPU 使用状況をプロファイリングしなさい。どのコードパスっがもっとも CPU を消費しているかを示しなさい。  
    解答)  
    Linux 実機が手に入ってから実施

* 6. (オプション、高度)iostat(1)と同様の表示(パスのリスト、書く方向のスループット、使用率の欄が含まれるようにする)で、物理バスやインターコネクトの使用率を表示するツール、bustop(1)を開発しなさい。可能なら飽和度とエラー指標を入れない、PMC を使うことが必要になるだろう。

## メモリ

- 1. メモリの用語についての以下の問いに答えなさい

  - メモリのページとは何か  
    解答)  
    OS と CPU が使う単位メモリ
  - 常駐メモリとは何か  
    解答)  
    現在メインメモリにあるメモリ
  - 仮想メモリとは何か  
    解答)  
    実際のメモリではない代替メモリ領域。
  - Linux 用語でページングとスワッピングはどのように異なるか  
    解答)  
    ページングは、メインメモリとスワップデバイスの間でのページ転送  
    スワッピングは、スワップデバイスへの無名ページング

  * 2. コンセプトについての以下の問いに答えなさい

    - デマンドページングの目的は何か  
      解答)  
      CPU に掛かるマッピング作成のオーバーヘッドを先延ばしする

    - メモリの使用率と飽和を説明しなさい  
      解答)  
      使用率はメモリの総量に対するする使用済みメモリの割合  
      飽和はメモリの使用量がメインメモリの総量を越えること

    - MMU と TLB の目的は何か  
      解答)  
      MMU:仮想アドレスからブル地アドレスの変換を行う。CPU キャッシュを参照する際に必要。  
      TLB:仮想アドレスから物理アドレスに変換するキャッシュ

    - ページアウトデーモンの役割は何か  
      解答)  
      ページアウトしたメモリを極力消さずにキャッシュに戻せるようにフリーリストの末尾に追加する

    * OOM キラーの役割は何か  
      解答)  
      プロセスを強制終了してメモリを解放する

  * 3. 以下の少し難しい問いに答えなさい

    - 無名ページングとは何か。ファイルシステムページングよりこの種のページングを分析する方が重要なのは何故か

      解答)  
      無名ページングは、ユーザーアプリの使用するヒープ・スタックを対象としており、ファイルシステムページングと異なり、必ずスワップデバイス、スワップファイルへのデータを必要とし、パフォーマンスを下げるので、なるべく発生しないようにチューニングする必要がある。

    - Linux ベースシステムでフリーメモリを使い切った時に、メモリを解放するためにカーネルが取る手順を説明しなさい  
      解答)

      - 1. ページキャッシュがあればページキャッシュの削除を行う
      - 2. スワッピング可能であれば最近使われてい以内ページをスワッピアプトして、フリーメモリを空ける
      - 3. リーピングによるメモリ解放
      - 4. OOM キラーにより、一部のプロセスを殺し、メモリを返す

    - スラブベースのアロケーションのパフォーマンス上の利点を説明しなさい

      解答)  
      固定サイズのデータ構造を用いることで、アロケーションのオーバーヘッドをかけずに、メモリの高速なリサイクルを可能にしている

  * 4. あなたの環境のために次のモノを作りなさい

    - メモリリソースのための USE メソッドチェックリスト。個々の指標の取得方法と結果の解釈方法。追加のソフトウェア製品をインストールしたり使ったりする前にが OS が提供する既存の可観測性ツールを使うようにしなさい

      解答)

      - 使用率:top -o %MEM で %MEM を見る

        ```
        masami@DESKTOP-L18OTEK /m/c/U/user [1]> top -o %MEM
        top - 09:46:33 up 4 min,  1 user,  load average: 0.11, 0.14, 0.07
        Tasks:  34 total,   1 running,  33 sleeping,   0 stopped,   0 zombie
        %Cpu(s):  0.2 us,  0.1 sy,  0.0 ni, 99.8 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
        MiB Mem :   3920.8 total,   3130.2 free,    441.5 used,    349.1 buff/cache
        MiB Swap:      0.0 total,      0.0 free,      0.0 used.   3266.9 avail Mem

        PID USER      PR  NI    VIRT    RES    SHR S  %CPU  %MEM     TIME+ COMMAND
        388 root      20   0  154352  71100  17948 S   0.0   1.8   0:06.54 python3.10
        177 root      20   0 1467084  39328  18196 S   0.0   1.0   0:01.20 snapd
        443 root      20   0   43172  37444  10048 S   0.0   0.9   0:02.96 python3
        207 root      20   0  107200  21316  12800 S   0.0   0.5   0:00.36 unattended-upgr
        174 root      20   0   30100  19156  10360 S   0.0   0.5   0:00.34 networkd-dispat
        43 root      19  -1   39532  14464  13492 S   0.0   0.4   0:00.31 systemd-journal
        129 systemd+  20   0   25528  12624   8428 S   0.0   0.3   0:00.50 systemd-resolve
          1 root      20   0  165840  11020   8084 S   0.0   0.3   0:01.45 systemd
        429 masami    20   0   16928   8744   7400 S   0.0   0.2   0:00.26 systemd
        399 masami    20   0  157724   7904   5888 S   0.0   0.2   0:01.49 fish
        435 masami    20   0  157556   7252   5620 S   0.0   0.2   0:00.14 fish
        178 root      20   0   15320   7220   6276 S   0.0   0.2   0:00.23 systemd-logind
        67 root      20   0   21952   5784   4408 S   0.0   0.1   0:00.36 systemd-udevd
        175 syslog    20   0  222400   5288   4464 S   0.0   0.1   0:00.04 rsyslogd
        400 root      20   0    7520   4724   3812 S   0.0   0.1   0:00.04 login
        150 message+  20   0    8616   4524   3872 S   0.0   0.1   0:00.10 dbus-daemon
        505 masami    20   0    7792   3684   3092 R   0.0   0.1   0:00.01 top
        ```

      - 飽和度:vmstat で swpd/si/so を見る。通常 0。
        ```
        masami@DESKTOP-L18OTEK /m/c/U/user> vmstat
        procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
        r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
        0  0      0 2959188  35796 534740    0    0    36    13   10   31  0  0 99  0  0
        ```
      - エラー:各社のツールを使用する？

    - メモリリソースのワークロードの特性の把握チェックリスト。個々の指標の取得方法を入れること。まず OS が提供する既存の可観測性ツールを使うようにしなさい。

      解答)

      - システム全体での物理/仮想メモリの使用率：  
        物理メモリ使用率＝ MemTotal-MemAvailable/MemTotal  
        仮想メモリ使用量＝ SwapTotal

      ```
      masami@DESKTOP-L18OTEK /m/c/U/user [1]> cat /proc/meminfo
      MemTotal:        4014868 kB
      MemFree:         3113680 kB
      MemAvailable:    3350992 kB
      Buffers:           44704 kB
      Cached:           380516 kB
      SwapCached:            0 kB
      Active:           138044 kB
      Inactive:         450540 kB
      Active(anon):       2516 kB
      Inactive(anon):   163948 kB
      Active(file):     135528 kB
      Inactive(file):   286592 kB
      Unevictable:           0 kB
      Mlocked:               0 kB
      SwapTotal:             0 kB
      SwapFree:              0 kB
      Dirty:                16 kB
      Writeback:             0 kB
      AnonPages:        153580 kB
      Mapped:           118072 kB
      Shmem:              3100 kB
      KReclaimable:      30452 kB
      Slab:              68088 kB
      SReclaimable:      30452 kB
      SUnreclaim:        37636 kB
      KernelStack:        2768 kB
      PageTables:         3412 kB
      NFS_Unstable:          0 kB
      Bounce:                0 kB
      WritebackTmp:          0 kB
      CommitLimit:     2007432 kB
      Committed_AS:     651020 kB
      VmallocTotal:   34359738367 kB
      VmallocUsed:       23164 kB
      VmallocChunk:          0 kB
      Percpu:             1760 kB
      AnonHugePages:     51200 kB
      ShmemHugePages:        0 kB
      ShmemPmdMapped:        0 kB
      FileHugePages:         0 kB
      FilePmdMapped:         0 kB
      HugePages_Total:       0
      HugePages_Free:        0
      HugePages_Rsvd:        0
      HugePages_Surp:        0
      Hugepagesize:       2048 kB
      Hugetlb:               0 kB
      DirectMap4k:       54272 kB
      DirectMap2M:     4139008 kB
      DirectMap1G:     8388608 kB
      ```

      - 飽和度：ページング(vmstat の si, so)、スワッピング(vmstat の swpd)、OOM キラーによる強制終了(cat /var/log/messages)
      - カーネル(cat /proc/meminfo の slab)とファイルシステムキャッシュ(sar -r の kbcached)のメモリ使用状況

      - プロセスごとの物理/仮想メモリの使用状況(ps aux の RSS が物理メモリ、VSZ が仮想メモリ)

      - メモリリソースコントロールがある場合はその設定状況  
        →wslconfig で 4G までになっている

  * 5. 以下の作業をしなさい

    - アプリケーションを選び、メモリアロケーションに至るコードパスの概要を説明しなさい  
      解答)  
      Linux の実機入手後

    - 次の Linux のスクリーンショットだけから見えるメモリアクティビティを説明しなさい  
      解答)  
      ディスクへの書き込み増加により、仮想メモリとして使用されているファイルシステムキャッシュがスワップアウトしている。また、ディスクの読み書き処理が詰まって、やや遅延が生じている状況。

  * 6. (オプション)カーネルの NUMA メモリ局所性ポリシーが実際にどの程度機能しているか示す指標を見つけなさい。指標のテストのために、メモリの局所性に優れていることが分かっているワークロードを開発しなさい

## ファイルシステム
* 1. ファイルシステムの用語についての以下の問いに答えなさい
  * 論理I/Oと物理I/Oの違いは何か。  
    解答)  
    論理I/O:アプリケーションがファイルシステムに対し発行するI/O要求  
    物理I/O:ファイルシステムがディスクに対し発行するI/O要求
  * ランダムI/OとシーケンシャルI/Oの違いは何か。  
    解答)  
    ランダムI/O:I/Oのファイルオフセットがランダム
    シーケンシャルI/O:IOのファイルオフセットが連続的。HDD等の回転ディスクでは回転量を減らす。
  * Direct I/Oとは何か。  
    解答)  
    ファイルシステム経由でファイルキャッシュを行わないI/O要求
  * ノンブロッキングI/Oとは何か。  
    解答)  
    処理中のI/O要求の終了を待たずに、エラーを即時返すI/O要求  
  * ワーキングセットサイズとは何か。  
    解答)  
    アプリケーションが現在使用しているファイルシステム領域
* 2. コンセプトについての以下の問いに答えなさい
  * VFSの役割は何か  
    解答)  
      異なるファイルシステムタイプに対する共通インターフェイスを提供する。ファイルシステム毎にプログラム制御を用意する必要がなくなる。
  * ファイルシステムレイテンシについて、特にどこでそれを計測できるかについて説明しなさい  
    解答)  
    ファイルシステムレイテンシは論理ファイルシステム要求を発行してから完了するまでの時間として計測される。アプリケーションやVFS、システムコールインターフェース等で計測できる。
  * プリフェッチ（先読み）の目的は何か。  
    解答)  
    ファイルI/Oのパフォーマンス改善を目的としている。シーケンシャルなI/Oを検出し、事前に要求されるであろうデータをキャッシュに載せる。
  * DirectI/Oの目的は何か。  
    解答)  
    物理I/Oのタイミングをアプリケーションで制御することが目的。  
* 3.　以下の少し難しい問いに答えなさい。
  * O_SYNCではなくfsync(2)を使うメリットを説明しなさい  
    解答)  
    fsyncはフラッシュを要求するだけなので、ある程度バッファに書き込みデータを溜めることで 物理I/Oを減らすことができるためパフォーマンスメリットが得られやすい。

  * read(2)/write(2)との比較でmmap(2)の利点、欠点を説明しなさい  
    解答)  
    mmapを使うことでよりコストの大きい物理I/Oを削減できる。欠点は、マルチプロセッサシステムで使用するとメモリの同期コストが掛かる。
  * 論理I/Oが物理I/Oになるとサイズが大きくなるのはどういうときかを説明しなさい  
    解答)  
    ファイル属性等や最終更新日時等のメタデータやI/Oサイズが切りのいいサイズに切り上げされる場合等に論理I/Oより物理I/Oのサイズが大きくなる場合がある。
  * 論理I/Oが物理I/Oになるとサイズが小さくなるのはどういうときかを説明しなさい  
    解答)  
    ファイルシステムのキャッシングや同じオフセットが複数回書き換えられることによる相殺機能が動作している場合、メモリマップドファイルを使用している場合に論理I/Oより物理I/Oの方が小さくなる場合がある。
  * ファイルシステムのCOWがパフォーマンスを向上させる仕組みを説明しなさい。  
    解答)  
    新しい位置にブロックを書き込むので、ランダムな書き込みをシーケンシャルな書き込みに変えることができる。また、複製を要求されたタイミングではなく、書き込み時に初めて複製を行うため、無駄なブロックを確保しなくて済む場合もある。
* 4. あなたの環境のために次のものを作りなさい  
  * ファイルシステムキャッシュをチューニングするためのチェックリスト。存在するファイルシステムキャッシュをリストアップし、現在のサイズ、使用状況、ヒット率をチェックする方法をまとめること。  
    解答)  
    現在のサイズ：free -h -w コマンドで確認(cacheがファイルシステムのキャッシュに相当)
    ```
    total        used        free      shared     buffers       cache   available
    Mem:           7.7Gi       975Mi       5.2Gi       182Mi        63Mi       1.5Gi       6.3Gi
    Swap:          2.0Gi          0B       2.0Gi
    ```
    ファイルシステムのキャッシュヒット率:dcstatコマンドで確認
    ```
    masami@masami-L ~> sudo dcstat-bpfcc
    In file included from <built-in>:2:
    In file included from /virtual/include/bcc/bpf.h:12:
    In file included from include/linux/types.h:6:
    In file included from include/uapi/linux/types.h:14:
    In file included from include/uapi/linux/posix_types.h:5:
    In file included from include/linux/stddef.h:5:
    In file included from include/uapi/linux/stddef.h:5:
    In file included from include/linux/compiler_types.h:122:
    include/linux/compiler-clang.h:41:9: warning: '__HAVE_BUILTIN_BSWAP32__' macro redefined [-Wmacro-redefined]
    #define __HAVE_BUILTIN_BSWAP32__
            ^
    <command line>:4:9: note: previous definition is here
    #define __HAVE_BUILTIN_BSWAP32__ 1
            ^
    In file included from <built-in>:2:
    In file included from /virtual/include/bcc/bpf.h:12:
    In file included from include/linux/types.h:6:
    In file included from include/uapi/linux/types.h:14:
    In file included from include/uapi/linux/posix_types.h:5:
    In file included from include/linux/stddef.h:5:
    In file included from include/uapi/linux/stddef.h:5:
    In file included from include/linux/compiler_types.h:122:
    include/linux/compiler-clang.h:42:9: warning: '__HAVE_BUILTIN_BSWAP64__' macro redefined [-Wmacro-redefined]
    #define __HAVE_BUILTIN_BSWAP64__
            ^
    <command line>:5:9: note: previous definition is here
    #define __HAVE_BUILTIN_BSWAP64__ 1
            ^
    In file included from <built-in>:2:
    In file included from /virtual/include/bcc/bpf.h:12:
    In file included from include/linux/types.h:6:
    In file included from include/uapi/linux/types.h:14:
    In file included from include/uapi/linux/posix_types.h:5:
    In file included from include/linux/stddef.h:5:
    In file included from include/uapi/linux/stddef.h:5:
    In file included from include/linux/compiler_types.h:122:
    include/linux/compiler-clang.h:43:9: warning: '__HAVE_BUILTIN_BSWAP16__' macro redefined [-Wmacro-redefined]
    #define __HAVE_BUILTIN_BSWAP16__
            ^
    <command line>:3:9: note: previous definition is here
    #define __HAVE_BUILTIN_BSWAP16__ 1
            ^
    3 warnings generated.
    TIME         REFS/s   SLOW/s   MISS/s     HIT%
    22:00:34:       609        5        4    99.34
    22:00:35:       484        4        3    99.38
    22:00:36:       464        4        3    99.35
    22:00:37:       605        4        3    99.50
    22:00:38:        38        0        0   100.00
    ```
    キャッシュサイズ：free -h -wのキャッシュ使用量とdcstat-bpfccのHIT列の積で求められる
  * ファイルシステムを操作するワークロードの特性の把握チェックリスト。個々の詳細情報の取得方法を入れること。まずOSが提供する既存の可観測性ツールを使うようにしなさい。  
    * オペレーションの頻度とタイプ  
    解答)  
    ```
    root@masami-L:~# bpftrace -e 'kprobe:vfs_* { @[func] = count(); }'
    Attaching 73 probes...
    ^C


    @[vfs_utimes]: 7
    @[vfs_unlink]: 7
    @[vfs_readlink]: 48
    @[vfs_write]: 104
    @[vfs_statx]: 854
    @[vfs_getattr_nosec]: 962
    @[vfs_open]: 971
    @[vfs_fstatat]: 1092
    @[vfs_read]: 1144
    ```
    VFSに対するオペレーションは上記で確認可能
    * ファイルI/Oのスループット  
        解答)  
    
    ```
    root@masami-L:~# fio -filename=/tmp/test2g -direct=1 -rw=read -bs=4k -size=2G -numjobs=64 -runtime=10 -group_reporting -name=file1
    file1: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=psync, iodepth=1
    ...
    fio-3.28
    Starting 64 processes
    file1: Laying out IO file (1 file / 2048MiB)
    Jobs: 20 (f=19): [R(1),E(2),_(1),E(1),_(3),E(2),R(2),E(1),R(1),E(5),R(1),E(4),R(1),E(2),f(1),E(1),R(1),E(3),R(1),E(4),R(2),E(1),R(1),E(1),R(2),E(7),R(1),E(1),R(2),E(1),R(1),E(2),R(2),E(2)][22.0%][r=185MiB/s][r=47.5k IOPS][eta 00m:39s]
    file1: (groupid=0, jobs=64): err= 0: pid=4377: Tue Oct 24 21:39:49 2023
      read: IOPS=52.5k, BW=205MiB/s (215MB/s)(2055MiB/10014msec)
        clat (usec): min=69, max=14200, avg=1215.34, stdev=659.58
        lat (usec): min=70, max=14200, avg=1215.49, stdev=659.58
        clat percentiles (usec):
        |  1.00th=[  334],  5.00th=[  457], 10.00th=[  529], 20.00th=[  644],
        | 30.00th=[  766], 40.00th=[  898], 50.00th=[ 1057], 60.00th=[ 1237],
        | 70.00th=[ 1467], 80.00th=[ 1729], 90.00th=[ 2147], 95.00th=[ 2507],
        | 99.00th=[ 3130], 99.50th=[ 3425], 99.90th=[ 4293], 99.95th=[ 4621],
        | 99.99th=[ 5538]
      bw (  KiB/s): min=155760, max=268860, per=100.00%, avg=210788.07, stdev=486.83, samples=1222
      iops        : min=38940, max=67214, avg=52695.97, stdev=121.70, samples=1222
      lat (usec)   : 100=0.01%, 250=0.20%, 500=7.51%, 750=21.06%, 1000=17.97%
      lat (msec)   : 2=40.34%, 4=12.76%, 10=0.15%, 20=0.01%
      cpu          : usr=0.31%, sys=1.08%, ctx=529046, majf=0, minf=868
      IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
        submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
        complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
        issued rwts: total=526132,0,0,0 short=0,0,0,0 dropped=0,0,0,0
        latency   : target=0, window=0, percentile=100.00%, depth=1

    Run status group 0 (all jobs):
      READ: bw=205MiB/s (215MB/s), 205MiB/s-205MiB/s (215MB/s-215MB/s), io=2055MiB (2155MB), run=10014-10014msec

    Disk stats (read/write):
      sda: ios=340990/2, merge=173800/1, ticks=421339/7, in_queue=421352, util=98.66%
    ```
    bwがスループットに相当。または、ddコマンドを使ってもいい。
    ワークロードに関する設問なので解答が的外れだったかもしれない。
    * ファイルI/Oのサイズ  
        解答)  
    読み出しバイト数のヒストグラム
    ```
    root@masami-L:~# bpftrace -e 'tracepoint:syscalls:sys_exit_read { @ = hist(args->ret); }'
    Attaching 1 probe...
    ^C

    @:
    [0]                  460 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
    [1]                    5 |                                                    |
    [2, 4)               226 |@@@@@@@@@@@@@@@@@@@@@@@@@                           |
    [4, 8)                74 |@@@@@@@@                                            |
    [8, 16)              445 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@  |
    [16, 32)               0 |                                                    |
    [32, 64)              46 |@@@@@                                               |
    [64, 128)             31 |@@@                                                 |
    [128, 256)             4 |                                                    |
    [256, 512)             6 |                                                    |
    [512, 1K)             71 |@@@@@@@@                                            |
    [1K, 2K)             163 |@@@@@@@@@@@@@@@@@@
    ```
      書き出しバイト数のヒストグラム
      ```
      root@masami-L:~# bpftrace -e 'tracepoint:syscalls:sys_exit_write { @ = hist(args->ret); }'
      Attaching 1 probe...
      ^C

      @:
      [0]                   15 |@@@                                                 |
      [1]                    8 |@@                                                  |
      [2, 4)                 3 |                                                    |
      [4, 8)                 0 |                                                    |
      [8, 16)              197 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
      [16, 32)               0 |                                                    |
      [32, 64)               2 |
      ```
    * 読み書きの比率  
        解答)  
      filetop-bpfccで確認可能
      ```
      21:47:19 loadavg: 0.31 0.21 0.09 1/460 1755

      TID    COMM             READS  WRITES R_Kb    W_Kb    T FILE
      1755   clear            2      0      60      0       R xterm
      1743   filetop-bpfcc    2      0      15      0       R loadavg
      615    irqbalance       7      0      7       0       R smp_affinity
      1755   clear            5      0      2       0       R libc.so.6
      615    irqbalance       2      0      2       0       R interrupts
      615    irqbalance       2      0      2       0       R stat
      442    systemd-oomd     1      0      1       0       R meminfo
      1755   clear            1      0      0       0       R libtinfo.so.6.3
      Detaching...
      ```
    * 同期書き込みの比率
    * ファイルオフセットへのランダムなアクセスとシーケンシャルなアクセス  
    解答)  
    readahead-bpfccで先読みのヒットと効率が確認できる  
    私の環境では失敗する・・・
    ```
    root@masami-L:~# readahead-bpfcc
    In file included from <built-in>:2:
    In file included from /virtual/include/bcc/bpf.h:12:
    In file included from include/linux/types.h:6:
    In file included from include/uapi/linux/types.h:14:
    In file included from include/uapi/linux/posix_types.h:5:
    In file included from include/linux/stddef.h:5:
    In file included from include/uapi/linux/stddef.h:5:
    In file included from include/linux/compiler_types.h:122:
    include/linux/compiler-clang.h:41:9: warning: '__HAVE_BUILTIN_BSWAP32__' macro redefined [-Wmacro-redefined]
    #define __HAVE_BUILTIN_BSWAP32__
            ^
    <command line>:4:9: note: previous definition is here
    #define __HAVE_BUILTIN_BSWAP32__ 1
            ^
    In file included from <built-in>:2:
    In file included from /virtual/include/bcc/bpf.h:12:
    In file included from include/linux/types.h:6:
    In file included from include/uapi/linux/types.h:14:
    In file included from include/uapi/linux/posix_types.h:5:
    In file included from include/linux/stddef.h:5:
    In file included from include/uapi/linux/stddef.h:5:
    In file included from include/linux/compiler_types.h:122:
    include/linux/compiler-clang.h:42:9: warning: '__HAVE_BUILTIN_BSWAP64__' macro redefined [-Wmacro-redefined]
    #define __HAVE_BUILTIN_BSWAP64__
            ^
    <command line>:5:9: note: previous definition is here
    #define __HAVE_BUILTIN_BSWAP64__ 1
            ^
    In file included from <built-in>:2:
    In file included from /virtual/include/bcc/bpf.h:12:
    In file included from include/linux/types.h:6:
    In file included from include/uapi/linux/types.h:14:
    In file included from include/uapi/linux/posix_types.h:5:
    In file included from include/linux/stddef.h:5:
    In file included from include/uapi/linux/stddef.h:5:
    In file included from include/linux/compiler_types.h:122:
    include/linux/compiler-clang.h:43:9: warning: '__HAVE_BUILTIN_BSWAP16__' macro redefined [-Wmacro-redefined]
    #define __HAVE_BUILTIN_BSWAP16__
            ^
    <command line>:3:9: note: previous definition is here
    #define __HAVE_BUILTIN_BSWAP16__ 1
            ^
    3 warnings generated.
    cannot attach kprobe, probe entry may not exist
    Traceback (most recent call last):
      File "/usr/sbin/readahead-bpfcc", line 98, in <module>
        b.attach_kprobe(event="__do_page_cache_readahead", fn_name="entry__do_page_cache_readahead")
      File "/usr/lib/python3/dist-packages/bcc/__init__.py", line 683, in attach_kprobe
        raise Exception("Failed to attach BPF program %s to kprobe %s" %
    Exception: Failed to attach BPF program b'entry__do_page_cache_readahead' to kprobe b'__do_page_cache_readahead'
    ```


* 5. 以下の作業をしなさい
  * アプリケーションを選び、ファイルシステムオペレーションのレイテンシの平均だけでなく、完全な分布を示すこと。
    * ファイルシステムオペレーションのレイテンシの平均だけでなく、完全な分布を示すこと。  
    解答)  
    ```
    root@masami-L:~# ext4dist-bpfcc
    In file included from <built-in>:2:
    In file included from /virtual/include/bcc/bpf.h:12:
    In file included from include/linux/types.h:6:
    In file included from include/uapi/linux/types.h:14:
    In file included from include/uapi/linux/posix_types.h:5:
    In file included from include/linux/stddef.h:5:
    In file included from include/uapi/linux/stddef.h:5:
    In file included from include/linux/compiler_types.h:122:
    include/linux/compiler-clang.h:41:9: warning: '__HAVE_BUILTIN_BSWAP32__' macro redefined [-Wmacro-redefined]
    #define __HAVE_BUILTIN_BSWAP32__
            ^
    <command line>:4:9: note: previous definition is here
    #define __HAVE_BUILTIN_BSWAP32__ 1
            ^
    In file included from <built-in>:2:
    In file included from /virtual/include/bcc/bpf.h:12:
    In file included from include/linux/types.h:6:
    In file included from include/uapi/linux/types.h:14:
    In file included from include/uapi/linux/posix_types.h:5:
    In file included from include/linux/stddef.h:5:
    In file included from include/uapi/linux/stddef.h:5:
    In file included from include/linux/compiler_types.h:122:
    include/linux/compiler-clang.h:42:9: warning: '__HAVE_BUILTIN_BSWAP64__' macro redefined [-Wmacro-redefined]
    #define __HAVE_BUILTIN_BSWAP64__
            ^
    <command line>:5:9: note: previous definition is here
    #define __HAVE_BUILTIN_BSWAP64__ 1
            ^
    In file included from <built-in>:2:
    In file included from /virtual/include/bcc/bpf.h:12:
    In file included from include/linux/types.h:6:
    In file included from include/uapi/linux/types.h:14:
    In file included from include/uapi/linux/posix_types.h:5:
    In file included from include/linux/stddef.h:5:
    In file included from include/uapi/linux/stddef.h:5:
    In file included from include/linux/compiler_types.h:122:
    include/linux/compiler-clang.h:43:9: warning: '__HAVE_BUILTIN_BSWAP16__' macro redefined [-Wmacro-redefined]
    #define __HAVE_BUILTIN_BSWAP16__
            ^
    <command line>:3:9: note: previous definition is here
    #define __HAVE_BUILTIN_BSWAP16__ 1
            ^
    3 warnings generated.
    Tracing ext4 operation latency... Hit Ctrl-C to end.
    ^C

    operation = open
        usecs               : count     distribution
            0 -> 1          : 93       |****************************************|
            2 -> 3          : 17       |*******                                 |
            4 -> 7          : 2        |                                        |
            8 -> 15         : 3        |*                                       |

    operation = read
        usecs               : count     distribution
            0 -> 1          : 130      |****************************************|
            2 -> 3          : 23       |*******                                 |
            4 -> 7          : 3        |                                        |
            8 -> 15         : 1        |                                        |
            16 -> 31         : 0        |                                        |
            32 -> 63         : 0        |                                        |
            64 -> 127        : 3        |                                        |
          128 -> 255        : 6        |*                                       |
          256 -> 511        : 4        |*                                       |
          512 -> 1023       : 0        |                                        |
          1024 -> 2047       : 0        |                                        |
          2048 -> 4095       : 0        |                                        |
          4096 -> 8191       : 0        |                                        |
          8192 -> 16383      : 0        |                                        |
        16384 -> 32767      : 0        |                                        |
        32768 -> 65535      : 1        |                                        |

    operation = fsync
        usecs               : count     distribution
            0 -> 1          : 0        |                                        |
            2 -> 3          : 0        |                                        |
            4 -> 7          : 0        |                                        |
            8 -> 15         : 0        |                                        |
            16 -> 31         : 0        |                                        |
            32 -> 63         : 0        |                                        |
            64 -> 127        : 0        |                                        |
          128 -> 255        : 0        |                                        |
          256 -> 511        : 0        |                                        |
          512 -> 1023       : 0        |                                        |
          1024 -> 2047       : 1        |**********                              |
          2048 -> 4095       : 0        |                                        |
          4096 -> 8191       : 4        |****************************************|
          8192 -> 16383      : 1        |**********                              |
        16384 -> 32767      : 0        |                                        |
        32768 -> 65535      : 1        |**********                              |

    operation = write
        usecs               : count     distribution
            0 -> 1          : 0        |                                        |
            2 -> 3          : 0        |                                        |
            4 -> 7          : 0        |                                        |
            8 -> 15         : 1        |**********                              |
            16 -> 31         : 4        |****************************************|
    ```
    * 個々のアプリケーションスレッドがファイルシステムオペレーションのために費やす時間の秒未満の部分を明らかにすること。  
    解答)  
    LatencyTopをインストールすれば確認可能。
  * マイクロベンチマークツールを使って、ファイルシステムキャッシュのサイズを実験的に調べなさい。使ったツールを選んだ理由を説明すること。また、ワーキングセットがキャッシングできなくなったときのパフォーマンス劣化を示しなさい（何らかの指標を使って）  
    解答)  
    やり方が分からなかった。書籍を見るにfioでやるっぽいので一応測定したけども。ベンチマークのうち2割はキャッシュヒットしてないため、処理速度が落ちていることはわかる。おそらく、ddコマンドで愚直にやっていけば分かるのだけど、設問の意図と異なる方法になる。
    ```
    [global]
    size=1G
    blocksize=4k
    ioengine=libaio
    iodepth=16
    directory=/tmp

    [read]
    rw=read
    ```
    ```
    masami@masami-L ~/Desktop [1]> fio --idle-prof=percpu bench.ini
    read: (g=0): rw=read, bs=(R) 4096B-4096B, (W) 4096B-4096B, (T) 4096B-4096B, ioengine=libaio, iodepth=16
    fio-3.28
    Starting 1 process
    Jobs: 1 (f=1): [R(1)][100.0%][r=385MiB/s][r=98.7k IOPS][eta 00m:00s]
    read: (groupid=0, jobs=1): err= 0: pid=2690: Sat Oct 28 17:39:41 2023
      read: IOPS=85.3k, BW=333MiB/s (349MB/s)(1024MiB/3074msec)
        slat (usec): min=2, max=3994, avg= 9.21, stdev=57.08
        clat (usec): min=2, max=1687, avg=163.88, stdev=195.87
        lat (usec): min=5, max=4433, avg=173.18, stdev=200.58
        clat percentiles (usec):
        |  1.00th=[   60],  5.00th=[   60], 10.00th=[   60], 20.00th=[   60],
        | 30.00th=[   60], 40.00th=[   60], 50.00th=[   60], 60.00th=[   61],
        | 70.00th=[   61], 80.00th=[  392], 90.00th=[  545], 95.00th=[  578],
        | 99.00th=[  717], 99.50th=[  816], 99.90th=[  955], 99.95th=[  963],
        | 99.99th=[ 1663]
      bw (  KiB/s): min=195432, max=425928, per=99.53%, avg=339506.67, stdev=76531.56, samples=6
      iops        : min=48858, max=106482, avg=84876.67, stdev=19132.89, samples=6
      lat (usec)   : 4=0.01%, 10=0.01%, 20=0.01%, 50=0.01%, 100=76.52%
      lat (usec)   : 250=0.05%, 500=11.70%, 750=10.88%, 1000=0.82%
      lat (msec)   : 2=0.02%
      cpu          : usr=14.03%, sys=40.38%, ctx=4113, majf=0, minf=28
      IO depths    : 1=0.1%, 2=0.1%, 4=0.1%, 8=0.1%, 16=100.0%, 32=0.0%, >=64=0.0%
        submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
        complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.1%, 32=0.0%, 64=0.0%, >=64=0.0%
        issued rwts: total=262144,0,0,0 short=0,0,0,0 dropped=0,0,0,0
        latency   : target=0, window=0, percentile=100.00%, depth=16

    Run status group 0 (all jobs):
      READ: bw=333MiB/s (349MB/s), 333MiB/s-333MiB/s (349MB/s-349MB/s), io=1024MiB (1074MB), run=3074-3074msec

    Disk stats (read/write):
      sda: ios=4103/0, merge=0/0, ticks=4253/0, in_queue=4253, util=89.77%

    CPU idleness:
      system: 82.35%
      percpu: 92.00%, 95.80%, 57.03%, 84.58%
      unit work: mean=56.06us, stddev=0.11
    ```
* 6. (オプション、高度)ファイルシステムに対する同期書き込みと非同期書き込みを計測する可観測性ツールを開発しなさい。頻度とレイテンシを表示し、発行したプロセスIDを突き止められるようにすること。また、ワークロード特性の把握にてきしたものにすること。  
    解答)  
    パス
* 7. (オプション、高度)間接的で大きくされたファイルシステムI/O、つまりアプリケーションが直接発行しないのに追加されたバイトとI/Oの統計を表示するツールを開発しなさい。ツールは、追加されたI/Oをタイプ別に分類し、理由を説明できなければならない。   
    解答)  
    パス
## ディスク
* 1. ディスクの用語についての以下の問いに答えなさい
  * IOPSとは何か  
    解答)  
    １秒あたりのディスクの読み書き回数
  * サービス時間と待ち時間の違いは何か  
    解答)  
    サービス時間:I/O処理時間
    待ち時間：I/O処理待ちキューに残っている時間
  * レイテンシ外れ値とは何か  
    解答)  
    異常にレイテンシの高いディスクI/O
  * ディスクの非データ転送コマンドとは何か  
    解答)  
    ディスクと外部のモジュール間でデータのやり取りがが発生しないコマンド。例えば、TRIMコマンドやディスクキャッシュのフラッシュ命令等。
* 2. コンセプトについての以下の問いに答えなさい
  * ディスクの使用率と飽和度について説明しなさい  
    解答)  
    使用率:ディスクがアクティブに作業を実行してビジー状態だった時間の割合  
    飽和度:OS内のデバイス待機キューの平均の長さとして計算される
  * ランダムディスクI/OとシーケンシャルディスクI/Oのパフォーマンスの違いを説明しなさい  
    解答)  
    回転式ディスクの場合は、シーク
  * 読み出しI/Oと書き込みI/Oにおけるオンディスクキャッシュの役割を説明しなさい  
    解答)  
    読み出しI/O:キャッシュからデータを読み取る場合、物理ディスクにアクセス不要になるためレイテンシが低くなる  
    書き出しI/O:キャッシュにデータを書き込み、物理ディスクへのアクセスは非同期で行うため、レイテンシが低くなる
    
* 3. 以下の少し難しい問いに答えなさい
  * 仮想ディスクの使用率（ビジー状態の割合）が誤解を招く理由を説明しなさい  
    解答)  
    * 仮想ディスクが複数の物理ディスクで構成されている場合、いずれかのディスクがずっとBUSYだと、I/O要求は処理できるものの使用率は100%で報告される。  
    ハードレイドで再構築中など、IO要求を発行していないときにBUSYの場合がある。  
    いずれにしても仮想ディスクの使用率は物理ディスクの使用率と一致しないことがある。
  * I/O待ち時間という指標が誤解を招く理由を説明しなさい  
    解答)  
    I/O待ち時間はI/Oキューで待機していた時間を示すが、キューから取り出された後のオンディスクにあるキューで待機している時間を含まなさい。オンディスクになった時点でI/Oサービス時間に含まれる。
  * RAID0(ストライピング)とRAID1(ミラーリング)のパフォーマンス特性を説明しなさい  
    解答)  
    RAID0は複数のドライブの間でI/Oを分割するので、I/OのパフォーマンスはRAID構成の中では最高になる。RAID1は読み出しパフォーマンスは優れているが、書き込みパフォーマンスは最も遅いディスクのスピードがボトルネックになり、オーバーヘッドは倍になる。
  * ディスクが過負荷になったときに、アプリケーションのパフォーマンスに対する影響を含めて何が起きるのかを説明しなさい  
    解答)  
    アプリケーションI/OとディスクI/Oが非同期の場合は、ディスクI/Oの劣化が直接アプリケーションに影響しない場合がある。一方、大きく影響する場合もあり、その場合はCPUがアイドル状態で待たされる
  * ストレージコントローラが過負荷になったとき（スループットがIOPSのどちらかで）、アプリケーションのパフォーマンスに対する影響を含めて何かが起きるのかを説明しなさい  
    解答)  
    単一のディスクコントローラが過負荷になった場合に、多量のディスクが接続されていｒｗに、ディスクコントローラがボトルネックになりパフォーマンスが発揮できないケースがある
* 4. あなたの環境のために次のものを作りなさい
  * ディスクリソース（ディスクとコントロータ）のためのUSEメソッドチェックリスト。個々の指標の取得方法（たとえば、どのコマンドを実行するか）と結果の解釈方法も入れること。追加のソフトウェア製品をインストールしたり使ったりする前に、ＯＳが提供する既存の可観測性ツールを使うようにしなさい  
    解答)  
    * ディスクデバイス
      * 使用率:iostat -x における、r/s + w/s + d/s + f/sが使用率に該当する(1秒あたりのBusy時間)。
      * 飽和度:iostas -xにおける、r/await + w/await + d/await + f/awaitが飽和度に該当する

      ```
      root@masami-L:~# iostat -x
      Linux 6.2.0-35-generic (masami-L)       11/01/2023      _x86_64_        (4 CPU)

      avg-cpu:  %user   %nice %system %iowait  %steal   %idle
                5.28    0.21    4.99    1.46    0.00   88.06

      Device            r/s     rkB/s   rrqm/s  %rrqm r_await rareq-sz     w/s     wkB/s   wrqm/s  %wrqm w_await wareq-sz     d/s     dkB/s   drqm/s  %drqm d_await dareq-sz     f/s f_await  aqu-sz  %util
      loop0            0.05      0.06     0.00   0.00    0.14     1.21    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.01
      loop1            0.18      1.35     0.00   0.00    2.19     7.50    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.05
      loop10           3.99     54.09     0.00   0.00    0.58    13.55    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.34
      loop11           0.69      5.15     0.00   0.00    2.91     7.49    0.00      0.00     0.00   0.00    0.00     0.00    0.00      0.00     0.00   0.00    0.00     0.00    0.00    0.00    0.00   0.21
      ```
  
      * エラー:bppftraceでブロックI/Oエラーをトレースする
      ```
      root@masami-L:~# bpftrace -e 't:block:block_rq_issue {@[args->rwbs] = count();}'
      Attaching 1 probe...
      ^C

      @[WM]: 32
      @[W]: 46
      @[FF]: 81
      @[WS]: 81
      @[N]: 284
      ```

    * ディスクコントローラ
      * 使用率:ベンダー提供ツールなので省略
      * 飽和度:ベンダー提供ツールなので省略
      * エラー:ベンダー提供ツールなので省略
  * ディスクリソースのワークロード特性の把握チェックリスト。個々の指標の取得方法を入れること。まずＯＳが提供する既存の可観測性ツールを使うようにしなさい  
    解答)  
    * I/Oの頻度: iostat -sxz のtps
    * I/Oスループット:iostat -sxz のkb / s
    * I/Oサイズ:iostat -x の*sz
    * 読み書きの割合:iostat -xの(r/s+w/s)/(r/s+w/s+d/s+f/s)
    * ランダムかシーケンシャルか:biopatterで確認可能らしい。https://github.com/brendangregg/bpf-perf-tools-book/blob/master/originals/Ch09_Disks/biopattern.bt
    
* 5. Linuxのiostatのこの出力だけからわかるディスクのふるまいを説明をしなさい  
    解答)  
    2つのディスクがあり、片方にI/Oが集中している。また、I/Oのほとんどは書き込み要求であるが秒あたりの処理は読み取りのほうが多い。読み取り処理でブロックされて、書き込み要求の処理待ちが増えている状況。
* 6. (オプション、高度)読み書き以外のすべてのディスクコマンドをトレースするツールを開発しなさい。SCSIレベルでのトレーシングが必要になる場合がある  
    解答)  
    
## ネットワーク
* 1. ネットワークの用語についての以下の問いに答えなさい。  
  * 帯域幅とスループットはどう違うか  
    解答)  
    帯域幅はデータ転送速度の上限。スループットはデータ転送速度を表す。
  * TCP接続レイテンシとは何か  
    解答)  
    ネットワーク接続を確立するまでの時間
  * TTFB(ファーストバイトレイテンシ)とは何か  
    解答)  
    接続が確立してから、データの先頭バイトが到達するまでの時間
  * RTT(ラウンドトリップ時間)とは何か  
    解答)  
    ネットワーク要求がエンドポイントの間で往復するために必要な時間
* 2. コンセプトについての以下の問いに答えなさい
  * ネットワークインターフェイスの使用率と飽和を説明しなさい  
    解答)  
    使用率：インターフェイスがフレームの送受信でビジーだった時間
    飽和度：インターフェイスの使用率が100%になったために発生したキューイング、バッファリング、ブロッキングの度合

    
  * TCPリスンバックログとは何か。どのようにして使うのか。  
    解答)  
    TCPハンドシェイクが確立した接続を保持するキュー
  * 割り込み一体化の長所・短所を説明しなさい  
    解答)  
    NICとの通信頻度が下がり、ネットワーキングのスループットは上がるが、レイテンシが少し高くなる。
* 3.以下の少し難しい問いに答えなさい
  * TCP接続でネットワークフレーム（またはパケット）エラーによってパフォーマンスが損なわれる仕組みを説明しなさい  
    解答)  
    受信側は送信側に再送要求を出し、送信側は再送するため、その分通信回数が増えて、レイテンシが高くなる。
  * ネットワークインターフェイスが要求によって過負荷になったとき、アプリケーションのパフォーマンスへの影響を含めて何が起きているか説明しなさい  
    解答)  
    通信要求がキューイングやバッファリングにより遅延したり、ブロッキングされることで失敗する可能性があり、アプリケーションのパフォーマンス低下や機能しない可能性がある。
* 4. あなたの環境のために次のものを作りなさい
  * ネットワークリソース（ネットワークインターフェイスとコントローラ）のためのUSEメソッドチェック度リスト。個々の指標の取得方法（たとえば、どのコマンドを実行するか）と結果の解釈方法も入れること。追加のソフトウェア製品をインストールしたり使ったりする前に、OSが提供する既存の可観測性ツールを使うようにしなさい  
    解答)  
    使用率:  nicstatの%Util
    ```
    root@masami-L:~# nicstat
    Time      Int   rKB/s   wKB/s   rPk/s   wPk/s    rAvs    wAvs %Util    Sat
    09:36:48       lo    2.32    2.32    4.21    4.21   564.7   564.7  0.00   0.00
    09:36:48  enp0s25    0.80    2.07    4.11    4.66   200.5   455.8  0.00   0.00
    ```
    飽和度: netstat -i のRX-OVR  
    エラー:netstat -i のTX-ERR
    ```
    root@masami-L:~# netstat -i
    カーネルインタフェーステーブル
    Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg
    enp0s25   1500     2098      0      2 0          2482      0      0      0 BMRU
    lo       65536     2142      0      0 0          2142      0      0      0 LRU
    ```
  * ネットワークリソースのワークロードの特性の把握チェックリスト。個々の指標の取得方法を入れること。まずOSが提供する既存の可観測性ツールを使うようにしなさい。  
    解答)  
    * ネットワークインターフェイスのスループット：RXとTXの1秒あたりのバイト数  
    netstat -c -iで差分から計算する。
    ```
    root@masami-L:~# netstat -c -i
    カーネルインタフェーステーブル
    Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg
    enp0s25   1500     1531      0      2 0          1937      0      0      0 BMRU
    lo       65536     1024      0      0 0          1024      0      0      0 LRU
    Iface      MTU    RX-OK RX-ERR RX-DRP RX-OVR    TX-OK TX-ERR TX-DRP TX-OVR Flg
    enp0s25   1500     1534      0      2 0          1939      0      0      0 BMRU
    lo       65536     1028      0      0 0          1028      0      0      0 LRU
    ```
    * ネットワークインターフェイスのIOPS:RXとTXの１秒あたりのフレーム数  
    nicstatのrPK/sとwPK/s
    ```
    root@masami-L:/etc/default# nicstat -z 1
    Time      Int   rKB/s   wKB/s   rPk/s   wPk/s    rAvs    wAvs %Util    Sat
    16:02:56       lo    1.36    1.36    5.27    5.27   263.4   263.4  0.00   0.00
    16:02:56  enp0s25    0.62    1.27    4.45    4.67   143.0   279.0  0.00   0.00
    ```
    * TCP接続の頻度：アクティブ接続とパッシブ接続の１秒あたりの接続数
    nstatを1秒間隔で実施し、その差分を確認する。0の項目は表示されない模様。TcpActiveOpensとTcpPassiveOpensから確認できる。
    ```
    root@masami-L:/etc/default# nstat
    #kernel
    IpInReceives                    76                 0.0
    IpInDelivers                    76                 0.0
    IpOutRequests                   74                 0.0
    TcpInSegs                       75                 0.0
    TcpOutSegs                      74                 0.0
    UdpIgnoredMulti                 1                  0.0
    Ip6InReceives                   2                  0.0
    Ip6InDelivers                   2                  0.0
    Ip6OutRequests                  2                  0.0
    Ip6InOctets                     113                0.0
    Ip6OutOctets                    121                0.0
    Ip6InNoECTPkts                  2                  0.0
    Icmp6InMsgs                     2                  0.0
    Icmp6OutMsgs                    2                  0.0
    Icmp6InEchos                    1                  0.0
    Icmp6InNeighborAdvertisements   1                  0.0
    Icmp6OutEchoReplies             1                  0.0
    Icmp6OutNeighborSolicits        1                  0.0
    Icmp6InType128                  1                  0.0
    Icmp6InType136                  1                  0.0
    Icmp6OutType129                 1                  0.0
    Icmp6OutType135                 1                  0.0
    TcpExtDelayedACKs               8                  0.0
    TcpExtTCPHPHits                 10                 0.0
    TcpExtTCPPureAcks               4                  0.0
    TcpExtTCPHPAcks                 34                 0.0
    TcpExtTCPOrigDataSent           43                 0.0
    TcpExtTCPDelivered              42                 0.0
    IpExtInBcastPkts                1                  0.0
    IpExtInOctets                   5324               0.0
    IpExtOutOctets                  5228               0.0
    IpExtInBcastOctets              72                 0.0
    IpExtInNoECTPkts                76                 0.0
    ```
* 5. 以下の作業をしなさい（動的トレーシングが必要になる場合がある）
  * アウトバウンド（アクティブ）TCP接続のTTFBの計測。  
    解答)  

    ```
    root@masami-L:/etc/default# tcpdump -i enp0s25 -tttt 'tcp and src host 127.0.0.1 and dst host example.com and dst port 80' -w captured_packets.pcap
    tcpdump: listening on enp0s25, link-type EN10MB (Ethernet), snapshot length 262144 bytes
    ^C0 packets captured
    0 packets received by filter
    0 packets dropped by kernel
    ```
    実際アクセスがあると次のような記録が残る
    ```
    2023-11-03 12:34:56.789012 IP 192.168.1.100.12345 > example.com.80: Flags [S], seq 1234567890, win 65535, options [mss 1460,sackOK,eol]
    ```
  * TCP接続レイテンシの計測。スクリプトは、ノンブロッキングconnect(2)呼び出しを処理しなければならない。  
    解答)  
    パス
* 6. (オプション・高度)RXとTXのTCP/IPインタースタックレイテンシを計測しなさい。RXでは割り込みからソケットの読み出しまでの時間を計測する。TXでは、ソケットへの書き込みからデバイスによる送信までの時間を計測する。負荷のもとでテストをしよう。レイテンシ外れ値の原因を説明するために、追加情報を組み込むことはできるか。  
    解答)  
    パス

## クラウドコンピューティング
* 1. 仮想化の用語について以下の問いに答えなさい
  * ホストとゲストの違いは何か

    解答)  
    ホストとは不特定多数の仮想環境を提供する物理システムを指す。  
    ゲストとはホストの提供する仮想環境。  
    ホストは提供する側。ゲストは利用側。
  * テナントとは何か
    
    解答)  
    ゲストと同義。ホストの提供する仮想環境。
  * ハイパーバイザーとは何か  
    解答)  
    ハードウェア仮想化において、仮想マシンインスタンスを管理する 
  * ハードウェア仮想化とは何か
    
    解答)  
    自前のカーネルを含むOS全体を実行できる仮想マシンを作る。  
* 2. コンセプトについて以下の問いに答えなさい
  * パフォーマンスの分離の役割を説明しなさい  
    解答)  
    同じホストを利用しているゲストが他のゲストに与える影響を極力を抑えることで、ゲストのリソースのバランスを保つ役割。

  * 最新のハードウェア仮想化(例えばNitro)のパフォーマンスオーバーヘッドを説明しなさい  
    解答)  
    Nitroの場合、ハードウェア支援によりゲストカーネル命令は無変換で処理されるため、オーバーヘッドなし。
    メモリのマッピングにおいては、ゲストのゲストの物理メモリからホストの物理メモリへ変換する際にオーバーヘッドが発生する。
    また、仮想環境のカーネル実行のためのRAM使用料が増える。
  * OS仮想化(たとえばLinuxコンテナ)のパフォーマンスオーバーヘッドを説明しなさい  
    解答)  
    マルチテナンシーによる競合。例えば、キャッシュのヒット率低下。CPU割り込み等。I/Oでもファイルシステムとネットワークパス構造のために、カーネル内で余分に呼び出しが発生する。
  * ハードウェア仮想化(XenかKVM)のゲストからの物理システムの可観測性について説明しなさい  
    解答)  
    特権ゲストからは高い水準で使用率・飽和・エラー・IOPSなどの物理リソースの使用状況を観察できる。通常はゲスト単位で観測可能。通常ゲストからは仮想化されたリソースは観測できるが物理リソースは全く観測できない。
  * OS仮想化のゲストからの物理システムの可観測性について説明しなさい  
    解答)  
　　自身の仮想環境のプロセス、ファイルシステム、ネットワークインターフェース、TCPセッションのみ観測できる。例外的にCPUやディスクなどシステム全体の統計値が取得できる。
  * ハードウェア仮想化（例えば、XenかKVM)と軽量ハードウェア仮想化（例えば、Firecracker)の違いを説明しなさい  
    解答)  
    軽量ハードウェア仮想化はサーバーに特化した軽量ハイパーバイザを使用するため、通常のハイパーバイザと異なり、ビデオ、オーディオ、BIOSその他デバイスのサポートをしていない。
* 3. 仮想化テクノロジをひとつ選び、ゲストについての以下の問いに答えなさい。  
  選択した仮想化テクノロジ：OS仮想化
  * メモリの使用制限がどのようにして適用され、ゲストからはどうすればそれがわかるか(システム管理者は、どうすればゲストがメモリを使い切っていることがわかるか)を説明しなさい  
    解答)  
    memory cgroup:limit_in_byteで設定する  
    基本的にゲストからは全体のメモリリソースしかわからない
  * CPUのリソースコントロールが構成されているとき、それがどのように適用されるのか、ゲストからはどうすればそれが分かるか説明しなさい  
    解答)  
    2種類ある。  
    cpuset cgroup:専用CPUを割り当てる。他のコンテナからは使用できないので割り込まれることもない。  
    cfs:cpu時間を割り当てる。バースティングにより極端にcpuを使用することがないように制限することもできる。  
    基本的にゲストからは全体のCPUリソースしか分からない
    

  * ディスクI/Oのリソースコントロールが構成されているとき、それがどのように適用されるのか、ゲストからはどうすればそれがわかるかを説明しなさい  
    解答)  
    blkio cgroup:weightでディスクリソースのシェアを決める  
    基本的にゲストからは全体のディスクリソースしか分からない
  * ネットワークI/Oのリソースコントロールが構成されているとき、それがどのように適用されるのか、ゲストからはどうすればそれがわかるかを説明しなさい  
    解答)  
    net_prio_group:アウトバウンドネットワークのトラフィックの優先度を設定
    ネットワークインターフェイスはゲストごとに観測できるようになっている。
* 4. リソースコントロールのためのUSEメソッドチェックリストを作りなさい。個々の指標の取得方法(たとえば、どのコマンドを実行するか)と結果の解釈方法も入れること。追加のソフトウェア製品をインストールしたり使ったりする前に、OSが提供する既存の可観測性ツールを使うようにしなさい  
    解答)  
    * CPU
    * メモリ
    * ファイルシステム
    * ディスク
    * ネットワーク
    基本的にはこれまでのUSEメソッドの流用になる。
    使用率や飽和度、エラーを確認する。ゲストで確認できないものは別の手段があれば使用する  
    繰り返し作業になりそうなのでだいぶ省略
--------
## ベンチマーキング
* 1. コンセプトについての以下の問いに答えなさい
  * マイクロベンチマーキングとは何か  
    解答)  
    人工的なワークロードを使って特定のタイプのオペレーションだけをテストするもの
  * ワーキングセットサイズとは何か。ストレージ関連のベンチマークの結果にどのような影響を及ぼすか。  
    解答)  
    アクセスされるデータのサイズ  
    メモリより遥かに小さいサイズにするとファイルシステムのキャッシュにのるのでファイルシステムのパフォーマンス調査になる  
    メモリより遥かに大きいサイズにするとキャッシュの効果を最低限にしてディスクI/Oのテストに近づける
  * 価格/パフォーマンス比を調べるのはなぜか  
    解答)  
    コストパフォーマンスが最高になるポイントを見つけるため
* 2. マイクロベンチマークツールを選び、次の課題を行いなさい
  * スレッド、I/Oサイズなどをスケーリングしてパフォーマンスを計測しなさい。  
    解答)  
    スレッドをスケーリング
    ```

    root@masami-L:~# fio -filename=/data/fio-test/testfile01 -direct=0 -rw=randread -bs=128k -size=10g -numjobs=1 -runtime=60 -group_rep
    orting -name=TestProgram1-io-perf-randomread -output=TestProgram1-io-perf-randomread.txt
    root@masami-L:~# (1)][100.0%][r=154MiB/s][r=1233 IOPS][eta 00m:00s]
    root@masami-L:~# fio -filename=/data/fio-test/testfile01 -direct=0 -rw=randread -bs=128k -size=10g -numjobs=2 -runtime=60 -group_rep
    orting -name=TestProgram1-io-perf-randomread -output=TestProgram1-io-perf-randomread.txt
    root@masami-L:~# (2)][100.0%][r=308MiB/s][r=2463 IOPS][eta 00m:00s]
    root@masami-L:~# fio -filename=/data/fio-test/testfile01 -direct=0 -rw=randread -bs=128k -size=10g -numjobs=4 -runtime=60 -group_rep
    orting -name=TestProgram1-io-perf-randomread -output=TestProgram1-io-perf-randomread.txt
    root@masami-L:~# (4)][100.0%][r=910MiB/s][r=7279 IOPS][eta 00m:00s]
    root@masami-L:~# fio -filename=/data/fio-test/testfile01 -direct=0 -rw=randread -bs=128k -size=10g -numjobs=8 -runtime=60 -group_rep
    orting -name=TestProgram1-io-perf-randomread -output=TestProgram1-io-perf-randomread.txt
    root@masami-L:~# (8)][100.0%][r=1182MiB/s][r=9459 IOPS][eta 00m:00s]
    root@masami-L:~# fio -filename=/data/fio-test/testfile01 -direct=0 -rw=randread -bs=128k -size=10g -numjobs=16 -runtime=60 -group_re
    porting -name=TestProgram1-io-perf-randomread -output=TestProgram1-io-perf-randomread.txt
    root@masami-L:~# [r(16)][100.0%][r=1261MiB/s][r=10.1k IOPS][eta 00m:00s]
    root@masami-L:~# fio -filename=/data/fio-test/testfile01 -direct=0 -rw=randread -bs=128k -size=10g -numjobs=32 -runtime=60 -group_re
    porting -name=TestProgram1-io-perf-randomread -output=TestProgram1-io-perf-randomread.txt
    root@masami-L:~# [r(32)][100.0%][r=1325MiB/s][r=10.6k IOPS][eta 00m:00s]
    root@masami-L:~# fio -filename=/data/fio-test/testfile01 -direct=0 -rw=randread -bs=128k -size=10g -numjobs=64 -runtime=60 -group_re
    porting -name=TestProgram1-io-perf-randomread -output=TestProgram1-io-perf-randomread.txt
    root@masami-L:~# [r(64)][100.0%][r=1378MiB/s][r=11.0k IOPS][eta 00m:00s]
    root@masami-L:~# fio -filename=/data/fio-test/testfile01 -direct=0 -rw=randread -bs=128k -size=10g -numjobs=128 -runtime=60 -group_r
    eporting -name=TestProgram1-io-perf-randomread -output=TestProgram1-io-perf-randomread.txt
    root@masami-L:~# : [r(128)][100.0%][r=1366MiB/s][r=10.9k IOPS][eta 00m:00s]
    root@masami-L:~# fio -filename=/data/fio-test/testfile01 -direct=0 -rw=randread -bs=128k -size=10g -numjobs=512 -runtime=60 -group_r
    eporting -name=TestProgram1-io-perf-randomread -output=TestProgram1-io-perf-randomread.txt
    root@masami-L:~# : [r(512)][100.0%][r=1159MiB/s][r=9274 IOPS][eta 00m:00s]
    ```
  * 結果をグラフにしなさい（スケーラビリティを明らかにする）  
    解答)  
    ![1](https://github.com/pea-sys/linux-experiments/assets/49807271/683d9371-9fa6-4db8-93f9-8d3e4d3d0e21)
  * マイクロベンチマークを使ってターゲットのパフォーマンスをピークまで引き上げ、制約要因を分析しなさい  
    解答)  
    並列度が256を超えるとIOPSが低下する。
    並列度を上げてパフォーマンスが落ちる要因はスレッドコンテキストにコストが掛かっていることになる。